{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f1c5852",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn.linear_model.base'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e05c7aaf70ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.linear_model.base'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize']=(20,10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cebb248",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv('bengaluru_house_price.csv')\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b5b303",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6138e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.groupby('area_type')['area_type'].agg('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b63911f",
   "metadata": {},
   "source": [
    "Now first task is to calculate the price...for that i dont need 'area_type','location','balcony','availability'columns.....for overall project i need that column but not for this calculation.....And this project is based on \"Supervised Learning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5350e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df1.drop(['area_type','location','balcony','availability'],axis='columns')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc923804",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.isnull().sum()\n",
    "# now using this we can get number of \"NaN\" values in all the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e10929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df2.dropna()\n",
    "df3.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509fd6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f423f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['size'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c056bb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['BHK']=df3['size'].apply(lambda x: int(x.split(' ')[0]))\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81249068",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['BHK'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b900c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['total_sqft'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcd1461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_float(x):\n",
    "    try:\n",
    "        float(x)\n",
    "    except:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005cd468",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[~df3['total_sqft'].apply(is_float)].head(10)\n",
    "# so like this we can get all the inputs which are in \"range\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c154771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sqft_to_num(x):\n",
    "    tokens=x.split('-')\n",
    "    if len(tokens)==2:\n",
    "        return (float(tokens[0])+float(tokens[1]))//2\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c15c30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_sqft_to_num('1195 - 1440')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6c892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=df3.copy()\n",
    "df4['total_sqft']=df4['total_sqft'].apply(convert_sqft_to_num)\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6242fd20",
   "metadata": {},
   "source": [
    "Upto here we have performed data cleaning.........\n",
    "Now from here we will do feature engineering......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d94ac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5=df4.copy()\n",
    "df5.drop(['society'],axis='columns',inplace=True)\n",
    "df5.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd977652",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['location']=df1.location.copy()\n",
    "df5.head()\n",
    "# len(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d4f1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df5.location.unique())\n",
    "df5['location']\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c3dc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df5.location.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4382ff5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['price_per_sqft']=df5['price']*100000/df5['total_sqft']\n",
    "\n",
    "df5.head()\n",
    "df5.location.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56105fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_stats=df5.groupby('location')['location'].agg('count').sort_values(ascending=False)\n",
    "location_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72761ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df5.location.unique())\n",
    "# here, applying encoding is difficult...so decrease the number of unique values...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae320df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_stats_less_than_10=location_stats[location_stats<=10]\n",
    "location_stats_less_than_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954170bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.location=df5.location.apply(lambda x:\"other\" if x in location_stats_less_than_10 else x)\n",
    "df5.location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124ff032",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df5.location.unique())\n",
    "# compare it with the upper one...now we can apply encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feda4fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c23dd4",
   "metadata": {},
   "source": [
    "now you have to be very practical when u work in poject like this...........\n",
    "....so here i am going to perform some operation to remove anomalies........"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae874870",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5[df5['total_sqft']/df5['BHK']<250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412aefec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d3e19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now this negation operation helps us to remove according to operation\n",
    "df6=df5[~(df5['total_sqft']/df5['BHK']<250)]\n",
    "df6.head()\n",
    "# print(len(df6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e70985",
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.price_per_sqft.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f82ce1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# now i am gonna keep the data which is in the range ---> (mean-standar_deviation)<=data<=(mean+standar_deviation)\n",
    "def remove_pps_outliers(df):\n",
    "    df_out = pd.DataFrame()\n",
    "    for key, subdf in df.groupby('location'):\n",
    "        m = np.mean(subdf.price_per_sqft)\n",
    "        st = np.std(subdf.price_per_sqft)\n",
    "        reduced_df = subdf[(subdf.price_per_sqft>(m-st)) & (subdf.price_per_sqft<=(m+st))]\n",
    "        df_out = pd.concat([df_out,reduced_df],ignore_index=True)\n",
    "    return df_out\n",
    "df7 = remove_pps_outliers(df6)\n",
    "df7.shape\n",
    "# (mean-standar_deviation)<=data<=(mean+standard_deviation) this formula is purely "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e5c3fe",
   "metadata": {},
   "source": [
    "one more anomaly which we noticed is that..... \n",
    "for a given location a 2BHK flats price cant be more than or equal to a 3 BHK flat's price.\n",
    "Now you can check this by using plt.scatter.....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa4cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter_chart(df,location):\n",
    "    bhk2 = df[(df.location==location) & (df.BHK==2)]\n",
    "    bhk3 = df[(df.location==location) & (df.BHK==3)]\n",
    "    matplotlib.rcParams['figure.figsize'] = (15,10)\n",
    "    plt.scatter(bhk2.total_sqft,bhk2.price,color='blue',label='2 BHK', s=50)\n",
    "    plt.scatter(bhk3.total_sqft,bhk3.price,marker='+', color='green',label='3 BHK', s=50)\n",
    "    plt.xlabel(\"Total Square Feet Area\")\n",
    "    plt.ylabel(\"Price (Lakh Indian Rupees)\")\n",
    "    plt.title(location)\n",
    "    plt.legend()\n",
    "    \n",
    "plot_scatter_chart(df7,\"Hebbal\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e11cc2",
   "metadata": {},
   "source": [
    "Removing those anomaly..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b467a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df7.groupby('location').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d607215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_bhk_outliers(df):\n",
    "    exclude_indices = np.array([])\n",
    "    for location, location_df in df.groupby('location'):\n",
    "        bhk_stats = {}\n",
    "        for bhk, bhk_df in location_df.groupby('BHK'):\n",
    "            bhk_stats[bhk] = {\n",
    "                'mean': np.mean(bhk_df.price_per_sqft),\n",
    "                'std': np.std(bhk_df.price_per_sqft),\n",
    "                'count': bhk_df.shape[0]\n",
    "            }\n",
    "        for bhk, bhk_df in location_df.groupby('BHK'):\n",
    "            stats = bhk_stats.get(bhk-1)\n",
    "            if stats and stats['count']>5:\n",
    "                exclude_indices = np.append(exclude_indices, bhk_df[bhk_df.price_per_sqft<(stats['mean'])].index.values)\n",
    "    return df.drop(exclude_indices,axis='index')\n",
    "df8 = remove_bhk_outliers(df7)\n",
    "# df8 = df7.copy()\n",
    "df8.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ac6927",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter_chart(df8,\"Rajaji Nagar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243e97ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams[\"figure.figsize\"] = (20,10)\n",
    "plt.hist(df8.price_per_sqft,rwidth=0.8)\n",
    "plt.xlabel(\"Price Per Square Feet\")\n",
    "plt.ylabel(\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6621120c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8.bath.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155ae8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8[df8.bath>=10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3eace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df8[df8.bath>df8.BHK+2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64732f0e",
   "metadata": {},
   "source": [
    "so remove this anomaly..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6209127",
   "metadata": {},
   "outputs": [],
   "source": [
    "df9=df8[df8.bath<=df8.BHK+2]\n",
    "len(df9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b224e95",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f86972",
   "metadata": {},
   "source": [
    "now we will start to make our model......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4bf02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df10=df9.drop(['size','price_per_sqft'],axis='columns')\n",
    "df10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ad4daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies=pd.get_dummies(df10.location)\n",
    "dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efeb0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df11=pd.concat([df10,dummies.drop('other',axis='columns')],axis='columns')\n",
    "df11.head()\n",
    "# now i can reduce one column i.e \"other\"...if all the element in a row is zero...\n",
    "# then it means that an element belongs to other column thats why we are dropping the \"other\" column.....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59daec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12=df11.drop(['location'],axis='columns')\n",
    "df12.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a72aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df12.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c3c3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df12.drop(['price'],axis='columns')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ed29a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df12.price\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea3ecb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ef4c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr_clf=LinearRegression()\n",
    "lr_clf.fit(X_train,y_train)\n",
    "lr_clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca69605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "\n",
    "cross_val_score(LinearRegression(), X, y, cv=cv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbafd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4842893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model_using_gridsearchcv(X,y):\n",
    "    algos={\n",
    "        'linear_regression':{\n",
    "            'model':LinearRegression(),\n",
    "            'params':{\n",
    "                'normalize':[True,False]\n",
    "            }\n",
    "        },\n",
    "        'lasso':{\n",
    "            'model':Lasso(),\n",
    "            'params':{\n",
    "                'alpha':[1,2],\n",
    "                'selection':['random', 'cyclic']\n",
    "            }\n",
    "        },\n",
    "        'decision_tree': {\n",
    "            'model': DecisionTreeRegressor(),\n",
    "            'params': {\n",
    "                'criterion' : ['mse','friedman_mse'],\n",
    "                'splitter': ['best','random']\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    }\n",
    "    \n",
    "    scores = []\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "    for algo_name, config in algos.items():\n",
    "#   here algo_name will have 'linear_regression','lasso' etc....and \"config\" will have their configuration like \"model\",\"params\"\n",
    "        gs =  GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False)\n",
    "        gs.fit(X,y)\n",
    "        scores.append({\n",
    "            'model': algo_name,\n",
    "            'best_score': gs.best_score_,\n",
    "            'best_params': gs.best_params_\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "\n",
    "find_best_model_using_gridsearchcv(X,y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32550ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_price(location,sqft,bath,bhk):    \n",
    "    loc_index = np.where(X.columns==location)[0][0]\n",
    "\n",
    "    x = np.zeros(len(X.columns))\n",
    "    x[0] = sqft\n",
    "    x[1] = bath\n",
    "    x[2] = bhk\n",
    "    if loc_index >= 0:\n",
    "        x[loc_index] = 1\n",
    "\n",
    "    return lr_clf.predict([x])[0]\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42db62c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_price('1st Phase JP Nagar',1000, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22d14dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_price('Indira Nagar',1000, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60352158",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_price('Indira Nagar',1000, 3, 3)\n",
    "# sometimes...in my given data we have found that...for a given location...3bhk flats price is less than\n",
    "# 2 bhk...so its data's fault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e102437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('banglore_home_prices_model.pickle','wb') as f:\n",
    "    pickle.dump(lr_clf,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ef5d93",
   "metadata": {},
   "source": [
    "now as my location is stored as columns...so i need a json file with all those columns in json format....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1837034a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "columns={\n",
    "    'data_columns':[col.lower() for col in X.columns]\n",
    "    \n",
    "}\n",
    "with open(\"columns.json\",'w') as f:\n",
    "    f.write(json.dumps(columns))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
